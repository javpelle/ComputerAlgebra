\documentclass[12pt, a5paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{soul}
\usepackage{amssymb}
\usepackage{hyperref}
\parindent 0in
\usepackage[spanish]{babel}
\setlength{\parskip}{0.5\baselineskip}
\usepackage{multirow}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage[twoside, margin=0.3in, bottom=0in, inner=0.5in, includefoot,heightrounded]{geometry}
\usepackage{multicol}

\fancyhf{} % clear all header and footers
\renewcommand{\headrulewidth}{0pt} % remove the header rule
\renewcommand{\footrulewidth}{0pt}
\setlength\footskip{10pt}
\fancyfoot[LO, RE]{\thepage}

\setlength{\columnsep}{0.3in}

\newtheorem*{teo}{\emph{$T^a$}}
\newtheorem*{prop}{Prop}

\theoremstyle{definition}
\newtheorem*{ejem}{Ejemplo}
\newtheorem*{defi}{Def}

\usepackage{listings}
\usepackage{color}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\lstset{
  columns=fullflexible,
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\ttfamily\footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  %deletekeywords={...},            % if you want to delete keywords from the given language
  inputencoding=utf8,
  %escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  literate= {á}{{\'a}}1 {α}{{$\alpha$}}1 {β}{{$\beta$}}1 {é}{{\'e}}1 
      {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1 {ñ}{{\~n}}1
			{Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
      {Ñ}{{\~N}}1 {δ}{{$\delta$}}1 {ε}{{$\epsilon$}}1 {φ}{{$\phi$}}1
			{_}{{\_}}1 {^}{{\textasciicircum}}1,
  frame=single,                    % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=haskell,                 % the language of the code
  morekeywords={ll,ii,vi,vii,vvi,vll,mii,ld,point,vect,line,circle,polygon},
            % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=1,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=4,                       % sets default tabsize to 2 spaces
  %title=\lstname,                   % show the filename of files included with \lstinputlisting; also try caption instead of title
  texcl=true
}

\pagestyle{fancy}

\begin{document}
\input{portada.tex}
\pagenumbering{gobble}
\pagenumbering{arabic}
\tableofcontents
\newpage
%\section{DPletario}
%\lstinputlisting[firstline=10]{dpletario.cpp}
%\newpage
\section{Introducción}
El objetivo de este documento es complementar mi práctica de ALCP.
Esto es así porque no me gusta poner comentarios excesivos en mi
código, así que prefiero dejar las explicaciones a parte.

He hecho la práctica en Haskell, porque es un paradigma de
programación mucho más cercano a los algoritmos que debemos
implementar. Esto permite en algunos puntos un código muy limpio.

A cambio, ha sido un poco engorroso tener que pasar
explícitamente las estructuras algebraicas sobre las que se trabaja
cada vez.

\newpage

\section{Definitions}
El primer módulo relevante es Definitions. Aquí se definen las
estructuras y algunos algoritmos básicos que se usarán en toda la
práctica.

En primer lugar, defino una estructura Dictionary, que contiene las
operaciones de cada estructura algebraica. He definido cuerpos,
dominios Euclídeos y dominios de factorización única. Para los
dominios euclídeos está definida una división que sólo se garantiza
que funciona al dividir por una unidad (O sea, cuando el grado es 1).

En este módulo también está el primer algoritmo importante: el
algoritmo de Euclides extendido. Es importante que está definido para
cualquier dominio Euclídeo. También hay algunos algoritmos similares
derivados.

También en Definitions está la exponenciación rápida en cualquier
anillo, y una pequeña función para calcular el orden de un elemento de
cualquier anillo.
\newpage\lstinputlisting[firstline=7]{../Definitions.hs}\newpage

\section{Utilities}
Utilities tiene funciones de ``fontanería'' de Haskell que he
preferido redefinir.

También tiene una criba de Eratóstenes muy refinada, (Utilizando
rotaciones y filtros sucesivos, junto con la evaluación perezosa).
Usando esta criba, he implementado un pequeño algoritmo de
factorización de enteros.
\newpage\lstinputlisting[firstline=1]{../Utilities.hs}\newpage

\section{Numbers, Fract y Gauss}
Los dos primeros son  módulos sencillos que no requieren mucha explicación.
Uno representa a los enteros (de precisión arbitraria) como dominio
euclídeo. Otro representa el cuerpo de fracciones asociado a un
dominio euclídeo.

En cuanto a Gauss, representa a los enteros de Gauss como dominio
euclídeo, usando como grado la norma euclídea. Para la división, hago
la división de los complejos usual y busco de las cuatro opciones
resultantes de sumar o no una unidad a cada coordenada, la que está
mas cerca.

Esto automáticamente resuelve el EEA para los enteros de Gauss. Es la
ventaja de la modularidad de mi práctica.

\newpage\lstinputlisting[firstline=5]{../Numbers.hs}
\lstinputlisting[firstline=6]{../Fract.hs}
\lstinputlisting[firstline=7]{../Gauss.hs}

\newpage

\section{Quotient}
Quotient define la operación de tomar el módulo de un dominio euclídeo
por un ideal generado por un elemento. Las operaciones son simplemente
tomar restos tras cualquier operación. Para la inversa, se aplica el
EEA para calcular el t válido. Es muy importante que esta versión
puede calcular divisiones cuando estas son posibles. Para ello,
manipulo un poco los resultados que da el EEA para que se resuelva la
ecuación en general.

Este módulo en particular es lo que hará falta más adelante para definir los
cuerpos finitos. En este caso, se toma $\mathbb{F}_p[x]/<f>$ donde f es un polinomio
irreducible. 

También se define un resoluto del Teorema del resto chino. Éste
funciona en cualquier dominio euclídeo cuando los módulos son primos
entre sí.

He implementado, para el caso de los enteros, un resolutor que permite
sistemas en que los módulos no son primos entre sí. Para esto, 
chineseSplit factoriza los módulos, descompone cada ecuación en un
conjunto de ecuaciones de módulo potencia de un primo. Luego,
chineseFilter elimina las ecuaciones redundantes comprobando que son
coherentes. Por último, se resuelve el sistema con el resolutor
general.

El motivo por el que implemento este resolutor es para resolver más
adelante el logaritmo discreto por Pollard-rho.

\newpage\lstinputlisting[firstline=6]{../Quotient.hs}\newpage

\section{Polynomials}
Polynomials es, obviamente, uno de los módulos más básicos de la
práctica. Genera el domino euclídeo de polinomios asociado a un
cuerpo. También está definido para dominios euclídeos, para poder más
adelante implementar la factorización en $\mathbb{Z}$.

Básicamente se implementan las operaciones con los algoritmos
elementales. Los polinomios se modelizan como listas de coeficientes,
de mayor a menor grado. 

Un detalle relevante es que para los polinomios, la función deg
devuelve una unidad menos que el grado del polinomio. Esto es porque
el grado como dominio euclídeo es diferente al grado del polinomio.
Para mantener la práctica coherente con los algoritmos, aquí el grado
es el grado euclídeo.

También se implementan algunas funciones que serán útiles más
adelante, como puede ser la reducción de un polinomio a su equivalente
mónico o la derivada.

\newpage\lstinputlisting{../Polynomials.hs}\newpage

\section{FiniteField}
El primero de los módulos interesantes, define los cuerpos finitos.
Nótese cómo se construyen. Se enumeran los polinomios mónicos, se
filtran los irreducibles (testeados con Rabin-Karp), y se elige uno
válido. La definición gestiona automáticamente cualquier problema que
pudiera surgir.

Los elementos del cuerpo finito, por tanto, se representan como listas
de elementos de $\mathbb{Z}$, de acuerdo con la base que define el
polinomio dado. Esto es lo que menos me gusta de mi práctica ya que
las definiciones posteriores de polinomios se hacen bastante
engorrosas.

El test de irreducibilidad es básicamente el mismo código que para los polinomios
en $\mathbb{F}_q[x]$, por el algoritmo de Rabin-Karp. Se pide que en
el candidato a cuerpo, el polinomio $x^{p^{deg f}}=1$, y que no ocurra
lo mismo con ningún grado menor.

\newpage\lstinputlisting{../FiniteField.hs}\newpage

\section{Factorization}
Aquí se implementa uno de los algoritmos centrales de la práctica:
Cantor-Zasenhaus. También se implementa Rabin-Karp para cuerpos
finitos, pero lo he quitado de este documento para simplificarlo.

Tal y como se describe en \cite{compalg}, se descompone en tres
partes:

\begin{enumerate}
  \item En la primera parte, se descompone el polinomio en factores
    libres de cuadrados, por el procedimiento de dividir sucesivamente
    por el mcd entre el polinomio y la derivada.

    Cuando la derivada se anula, hay que tener un poco de cuidado. En
    este caso, se puede hacer la sustitución $x:=x^{1/p}$ y seguir
    iterando el algoritmo.

  \item En la segunda parte, se descompone el polinomio en factores de
    tal forma que cada uno de esos factores se descomponga en
    irreducibles del mismo grado. Este paso es muy sencillo usando el
    resultado de que el producto de todos los polinomios irreduciles
    de grado divisor de k es $x^{q^k}-x$. De esta forma, se realizan divisiones
    sucesivas por el mcd entre el polinomio dado y $x^{q^k}-x$. Como
    esto sería prohibitivamente lento, se aplica la optimización
    adicional de considerar las operaciones módulo f.

\newpage\lstinputlisting[firstline=8,lastline=48]{../Factorization.hs}\newpage

  \item El tercer paso es el algoritmo de Cantor-Zassenhaus
    propiamente dicho. Es un algoritmo probabilista tipo Las Vegas en
    que se aplica la idea de que $\mathbb{F}_q[x]/f$ es producto
    directo de los cuerpos análogos para los divisores. Puesto que
    sabemos cuantos elementos hay en cada subanillo, la probabilidad
    de que tomando un elemento h al azar, g divida alguno de los factores
    es aproximadamente $1/2$.

    Los algoritmos probabilistas en Haskell tienen una cierta
    dificultad de programación añadida por la transparencia
    referencial. Por esto, la generación de números aleatorios se
    realiza en una lista de elementos que se van usando como testigos.


\newpage\lstinputlisting[firstline=49]{../Factorization.hs}\newpage
\end{enumerate}

\section{Miller-Rabin y AKS}
  Estos son dos algoritmos de testeo de primalidad, uno probabilista
  tipo Las Vegas y otro determinista. Los muestro juntos porque es
  interesante compararlos.

  El algoritmo de Miller-Rabin se basa en un lema sobre las raices
  cuadradas de la unidad. Si $x^2\equiv 1 \mod p$, entonces,
  $(x+1)*(x-1)\equiv 0 \mod p$. Por tanto, $x\equiv \pm 1 \mod p$.
  Entonces, si n es primo impar, $n-1=2^r*s$ es par (con s impar).
  Entonces, dado un $a\in \mathbb{Z}/<n>$ se tiene que $a^d\equiv 1
  \mod n$ o $a^{2^t*d}\equiv -1 \mod n$ para algún $0\leq r\leq s-1$.
  Entonces, simplemente se prueba con testigos aleatorios. La
  probabilidad de que eun testigo aleatorio demuestre la reducibilidad
  de un compuesto es al menos $3/4$. Con suficientes pruebas se reduce
  muy rápido la probabilidad de que un número sea primo.

  Sin embargo, el problema de encontrar un algoritmo en P (es decir,
  determinista y polinómico) para comprobar la primalidad se resuelve
  por primera vez con AKS. Se trata de que en $\mathbb{Z}_n$ se cumple
  el ``sueño del novato'' si a es coprimo con n: $(x-a)^n\equiv(x^n)-a \mod n$ 

  Para hacer la prueba de forma eficiente, se toma módulo un cierto
  polinomio de la forma $x^r-1$. La clave en AKS es encontrar una cota
  para ese r.

  Aunque el AKS es determinista y polinómico, se porta realmente mal
  en comparación con Miller-Rabin. Hacen falta mejoras sugeridas por
  Lenstra entre otros para hacer que sea minimamente práctico.

\newpage\lstinputlisting[firstline=11]{../MillerRabin.hs}
\lstinputlisting[firstline=10]{../AKS.hs}\newpage

\section{Logarithm}
  Como el enunciado no especificaba el algoritmo para el logaritmo
  discreto, he elegido el algoritmo rho de Pollard, que se basa en una
  idea que ya conocía para la factorización de enteros.

  El algoritmo genera congruencias que debe cumplir el logaritmo
  buscado. Estas congruencias son módulo divisores de $q-1$, lo que
  me obligó a implementar un Teorema chino del resto a prueba de
  ecuaciones no primas entre sí.

  La idea es que si buscamos $\gamma$ con $\alpha^\gamma=\beta$,
  podemos reducir el problema a encontrar (a,b,a',b') con
  $\alpha^a*\beta^b=\alpha^{a'}*\beta^{b'}$, y luego resolver una
  ecuación simple. Estos (a,b,a',b') se encuentran creando una
  sucesión $\alpha^{a_i}*\beta^{b_i}$. Si la secuencia es
  determinista, entrará en un bucle y tendremos dos pares de números
  que verifiquen la propiedad.

  Entonces, creo una sucesión determinista sobre los exponentes para
  encontrar ese punto en que se repite, usando el algoritmo de Floyd
  de la tortuga y la liebre. Se trata de iterar por una parte $f$ y
  $f\circ f$ hasta que lleguen al mismo punto.
\newpage\lstinputlisting{../Logarithm.hs}\newpage
  
\section{Hensel}
  En este módulo se aplica el lema de Hensel para factorizar un f
  libre de cuadradosen
  $\mathbb{Z}[x]$. Para ello se sigue
  un proceso en cinco pasos explicado en \cite{CompAlg}: primero, se
  elige un p de tal forma que no se anule el coeficiente principal y
  que siga siendo libre de cuadrados. El segundo paso es factorizar f
  en ese cuerpo finito.
 
  El tercer paso es elegir un N de tal forma que una
  factorización en $\mathbb{Z}/<p^N>$, tenga todos los coeficientes de
  la factorización real. Esto se logra con las cotas de Mignotte.

  El cuarto paso es elevar esa factorización usando Hensel. Es
  relativamente directo elevar una factorización de dos polinomios.
  Hace falta tener un poco de cuidado para extender esa idea a varios.

  Por último, se recombinan los factores. Yo en realidad calculo los
  divisores, compruebo cuales son divisores reales, y luego identifico
  los factores. No se puede hacer mucho más eficiente, ya que este
  algoritmo es exponencial.

  \newpage\lstinputlisting[firstline=11,lastline=53]{../Hensel.hs}\newpage

  El punto más delicado del algoritmo es extender la elevación a los
  múltiples factores. Hay que considerar la factorización como un
  producto entre el primero y los demás, luego, tras la elevación, se
  repite el proceso, indicando como polinomio producto el segundo
  resultado de la elevación.

  Este proceso se repite tantas veces como indique la cota de
  Mignotte.

  \newpage\lstinputlisting[firstline=55]{../Hensel.hs}\newpage

\end{document}
